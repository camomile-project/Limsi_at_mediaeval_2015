% This is "sig-alternate.tex" V2.0 May 2012
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012



\documentclass{acm_proc_article-me}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{multirow}


\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{url}


\begin{document}
%
% --- Author Metadata here ---

%Copyright is held by the author/owner(s).

\conferenceinfo{MediaEval 2015 Workshop}{Sept. 14-15, 2015, Wurzen, Germany}

%\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{LIMSI at MediaEval 2015: \\ Person Discovery in Broadcast TV Task}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{1}

\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Johann Poignant, Herv\'e Bredin, Claude Barras \\
       \affaddr{LIMSI - CNRS - Rue John Von Neumann, Orsay, France.}
       \email{firstname.lastname@limsi.fr}
\\
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
\date{30 July 2015}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}

This paper describes the algorithm tested by the LIMSI team in the MediaEval 2015 Person Discovery in Broadcast TV Task. For this task we used an audio/video diarization process constrained by names written on screen. These names are used to both identify clusters and prevent the fusion of two clusters with different co-occurring names. This method obtained 83.1\% of EwMAP tuned on the out-domain development corpus.

\end{abstract}


\section{Introduction}

We present the approach of the LIMSI team to the Person Discovery in Broadcast TV Task at MediaEval 2015. To address this task we had to return the names of people who can be both seen as well as heard in a selection of shots in a collection of videos. The list of people is not known \emph{a priori} and their names must be discovered in an unsupervised way from media content using text overlay or speech transcripts. For further details about the task, dataset and metrics the reader can refer to the task description~\cite{POIGNANT--MEDIAEVAL--2015}.

We first detail the fusion system baseline provided to all participants (we are both organizer and participant). Then, we describe the constrained multi-modal clustering. Finally, we compare the results obtained.

\section{Multi-modal fusion}

We propose two different approaches to address the task. They only rely on metadata provided to all participants (see Table~\ref{tab:subcomp}). Only written names are used as source of identity. In addition to speech turn segmentation and face detection and tracking, the baseline relies on the provided speaker diarization and speaking face mapping. The constrained clustering relies on the similarity matrices (for speaker and face) to process its own clustering.

\begin{table}[ht]
  \centering
  \begin{tabular}{|l|c|c|}
    \hline
	\multirow{2}{*}{Components}	& \multirow{2}{*}{Baseline}	& Constrained 		\\
									&							& clustering 		\\
	\hline
	\hline
	\multicolumn{3}{|c|}{Speech turns}												\\
	\hline
	Segmentation						&			x				&		x			\\
	Similarity						&							&		x			\\
	Diarization						&			x				&					\\
	\hline
	\multicolumn{3}{|c|}{Face}														\\
	\hline
	Detection \& Tracking			&			x				&		x			\\
	Similarity						&							&		x			\\
	Diarization						&							&					\\
	\hline
	\multicolumn{3}{|c|}{Speaking face}												\\
	\hline
	Mapping							&			x				&		x			\\
	\hline
	\multicolumn{3}{|c|}{Source of names}											\\
	\hline
	Written names~\cite{POIGNANT--ICME--2012}	&		x		&		x			\\
	Pronounced names~\cite{LAMEL--IWSLT--2011, DIANRELLI--IJCNLP--2011}	&	&		\\
	\hline
  \end{tabular}
  \caption{Sub-component provided used by fusions}
  \label{tab:subcomp}
\end{table}


\subsection{Baseline}

From the written names and the speaker diarization, we used the ``Direct Speech Turn Tagging'' method described in~\cite{POIGNANT--INTERSPEECH--2012} to identify speaker: we first tagged speech turns with co-occurring written name. Then, on the remaining unnamed speech turns, we find the one-to-one mapping that maximizes the co-occurrence duration between speaker clusters and written names (see~\cite{POIGNANT--INTERSPEECH--2012} for more details). Finally, we propagate the speaker identities on the co-occurring face tracks based on the speech turns/face tracks mapping.

\begin{figure}[htb]
 \centering
 \includegraphics[width=0.9\linewidth]{figs/baseline.pdf}
 \caption {Baseline fusion system overview}
 \label{fig:gene}
\end{figure}


\subsection{Constrained multi-modal clustering}

Figure~\ref{fig:gene} shows a global overview of our method. We first combined the mono-modal similarity matrix and the speaking face mapping into a large multi-modal matrix using weights $\alpha$ and $\beta$ to give more or less importance to a given modality. In parallel, written names are used to identify co-occurring face tracks and speech turns.

\begin{figure}[htb]
 \centering
 \includegraphics[width=0.9\linewidth]{figs/schema_clus_contraint.pdf}
 \caption {Constrained clustering overview}
 \label{fig:gene}
\end{figure}

Then, we perform an agglomerative clustering on the multi-modal matrix to merge all face tracks and speech turns of a same person into a unique cluster. This process is constrained by avoiding the fusion of clusters named differently. The two parameters $\alpha$ and $\beta$ advance or delay the merge of components of a modality relatively to others during the agglomerative clustering process, while the stopping criterion is chosen to maximize the target metrics (here the EwMAP). A complete description of this method can be found in~\cite{POIGNANT--MTAP--2015}.

\subsection{Speaking face selection and confidence}

The last part is common for the two fusions. For each person who speaks and appears in a shot (following the shot segmentation provided to all participants), we compute a confidence score. This score is based on the temporal distance between the speaking face and its closest written name. This confidence equals to:
\begin{align*}
  \text{confidence} = & \left\{
  	\begin{array}{ll}
  		1+d  & \mbox{if the speaking face co-occurs}  \\
  		 	 & \mbox{with the written name}		\\
  		1/\delta &\mbox{otherwise}
  	\end{array}
  \right.
\end{align*}

\noindent where $d$ is the co-occurrence duration and $\delta$ is the duration of the gap between the face track (or speech turn) and the written name.

\section{Results}

In Table~\ref{tab:results}, we report the EwMAP, the MAP and the Correctness (denoted by $C$ ) obtained by the baseline and our system tuned on an out-domain corpus (for the first deadline: 01-jul-15) and on an in-domain corpus (second deadline: 08-jul-15).

The baseline does not take into account the similarity between face and does not benefit from the knowledge of written names during the diarization process. In addition to these 2 additional information, our second method optimizes the stopping criterion of the clustering based on the target metric (EwMAP) while the diarization of the baseline is tuned to maximize the classical DER.


\begin{table}[ht]
  \centering
  \begin{tabular}{|l|c|c|c|}
    \hline
	Run 											& EwMAP(\%)	& MAP(\%)	& C(\%) \\
	\hline
	\hline
	baseline										& 78.35		& 78.64		& 92.71		\\
	\hline
	limsi 01-jul-15 								& 83.13		& 83.46		& 93.19		\\
	limsi 08-jul-15 								& 84.56		& 84.89		& 94.11		\\
	\hline
	\hline
	Oracle propagation 	& \multirow{2}{*}{96.84}		& \multirow{2}{*}{96.84}		& \multirow{2}{*}{97.25}	\\
	mono-show			&							&							&			\\
	\hline
	Oracle propagation 	& \multirow{2}{*}{97.83}		& \multirow{2}{*}{97.83}		& \multirow{2}{*}{97.83}	\\
	cross-show 			&							&							&			\\
  	\hline
  \end{tabular}
  \caption{Results}
  \label{tab:results}
\end{table}

For the first deadline (July 1st) we tuned the parameters $\alpha$ and $\beta$ and the stopping criterion of the clustering process on the out-domain development set. For the second deadline (July 8th), we tuned these parameters with the evaluation proposed via the leaderboard (computed every six hours on a subset of the test set). We can see only a little improvement between them, showing that our method generalizes well.

To determine the scope for further progress we used an oracle capable of recognizing a speaking face as soon as his/her written name is correctly extracted by the OCR module. In the mono-show case, the name must be written in the same video. In the cross-show case, the name can be written in any video of the corpus. Since our own approach only uses mono-show propagation, these oracle experiments show it is possible to earn up to 1\% of MAP using cross-show propagation approaches.

In Table~\ref{tab:precions_and_recall} we report the mean precision and recall over all queries. Compared to the baseline, the constraints on the clustering process allows to have a lower stopping criterion (therefore to have bigger clusters and hence to improve the recall), while keeping very good clusters purity (see the precision in Table~\ref{tab:precions_and_recall}). The high precision of our constraint clustering made the choice of the confidence score (used to rank shots in the computation of the MAP) not really important. The tuning of the three parameters on an in-domain corpus improves recall by 1.3\% and decreases precision by 0.8\%. In practice, $\alpha$ was reduced for the July 8th (in-domain tuning), therefore speech turns clustering was delayed (with respect to face tracks clustering) between July 1st (out-domain) and July 8th (in-domain tuning).

\begin{table}[ht]
  \centering
  \begin{tabular}{|l|c|c|}
    \hline
	Run 				& Precision(\%)	& Recall(\%)		\\
	\hline
	\hline
	baseline			& 79.1			& 74.8			\\
	\hline
	limsi 01-jul-15 	& 98.5			& 82.9			\\
	limsi 08-jul-15 	& 97.7			& 84.2			\\
  	\hline
  \end{tabular}
  \caption{Mean precision and recall}
  \label{tab:precions_and_recall}
\end{table}

%In the next table (\ref{tab:errors}) we detail the numbers of queries who was well or bad answered. From the 2070 queries, 634 correspond to persons who neither speak and appear in the shots selected on test set. For 14/15 of them, our system return shots (the half of them are due to annotations errors).
%
%On the 1436 remaining queries, we return at least one correct shot for 1251/1267 and 4/9 queries where no shot returns are correct. From the 44 queries without written names available and neither shot return, 33 hypotheses corresponding to the queries have too many transcription errors to be mapped with the reference.
%
%The 137 queries (01-jul-15) where a written name is available correspond to 648 shots in the reference. Only 214 of them were in a video where a written name is extracted, 434 of them need a cross-show propagation to be find (respectively 632, 199 and 433 for the second dead-line)
%
%
%\begin{table}[ht]
%  \centering
%  \begin{tabular}{|l|c|c|}
%    \hline
%			 											& 01-jul-15				& 08-jul-15				\\
%	\hline
%	\hline
%	\#queries \textcircled{\tiny{0}}						& \multicolumn{2}{|c|}{2070}						\\
%
%	\hline
%	\textcircled{\tiny{0}} without any speaking 			& \multicolumn{2}{|c|}{\multirow{2}{*}{634}}		\\
%	face in the reference \textcircled{\tiny{1}} 		& \multicolumn{2}{|c|}{} 						\\
%
%	\hline
%	\textcircled{\tiny{1}} where our system return		& \multirow{2}{*}{14}	& \multirow{2}{*}{15} 	\\
%	at least 1 shot										&  						&						\\
%
%	\hline
%	\textcircled{\tiny{0}} with at least 1 speaking		& \multicolumn{2}{|c|}{\multirow{2}{*}{1436}}	\\
%	face in the reference \textcircled{\tiny{2}}			& \multicolumn{2}{|c|}{} 						\\
%
%	\hline
%	\textcircled{\tiny{2}} with at least 1 correct shot	& \multirow{2}{*}{1251}	& \multirow{2}{*}{1267} 	\\
%	return 												&  						&						\\
%
%	\hline
%	\textcircled{\tiny{2}} with all shots return wrong 	& 4						& 9				 		\\
%
%	\hline
%	\textcircled{\tiny{2}} with written names available 	& \multirow{2}{*}{137}	& \multirow{2}{*}{116} 	\\
%	and no shot return 									&  						&						\\
%
%	\hline
%	\textcircled{\tiny{2}} without written names			& \multicolumn{2}{|c|}{44 (33 written names} 	\\
%	available and neither shot return					& \multicolumn{2}{|c|}{with too many errors)} 	\\
%
%  	\hline
%  \end{tabular}
%  \caption{Detail on results}
%  \label{tab:errors}
%\end{table}



\section{Conclusion and future works}

This paper presented our approach and results at the MediaEval Person Discovery in Broadcast TV task. The process used an audio/video diarization constrained by written names on screen.
This source of identities is used to both identify clusters and avoid wrong merges during the agglomerative clustering process.

For future works we will improve the distance between speech turns, try other clustering methods and cross-show propagation. \\


\noindent\textbf{Acknowledgment.} This work was supported by the French National Agency for Research under grant ANR-12-CHRI-0006-01 (CAMOMILE project).

\newpage

% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{publi}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references


\end{document}
